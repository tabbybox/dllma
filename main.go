package main

import (
	"bytes"
	"encoding/json"
	"fmt"
	"net/http"
	"os"
	"strings"
)

func main() {
	httpc := &http.Client{}

	logFile, err := os.OpenFile("log.txt", os.O_RDWR|os.O_CREATE|os.O_APPEND, 0666)
	if err != nil {
		fmt.Println("Error opening log file:", err)
		return
	}
	lastAnswer := "Talk about stuff"

	for i := 0; i < 80; i++ {
		// fmt.Println("", lastAnswer)
		lastAnswer = sendToModel(httpc, lastAnswer)
		str := "\n>> " + lastAnswer + "\n"
		logFile.WriteString(str)
		fmt.Print(str)
	}
	// answer := sendToModel(httpc)

}

func sendToModel(httpc *http.Client, prompt string) string {
	marshalledJson, err := json.Marshal(OllamaGenerateBody{
		Model:  "llama2-uncensored",
		Prompt: prompt,
		Stream: false,
	})
	if err != nil {
		fmt.Println("Error marshalling JSON:", err)
	}
	body := []byte(marshalledJson)
	req, err := http.NewRequest("POST", "http://localhost:11434/api/generate", bytes.NewBuffer(body))
	if err != nil {
		fmt.Println("Error creating HTTP request:", err)
		// return nil, err// Generated by https://quicktype.io
	}

	req.Header.Set("Content-Type", "application/json")

	response, err := httpc.Do(req)
	if err != nil {
		fmt.Println("Error sending HTTP request:", err)
		// return nil, err
	}
	defer response.Body.Close()

	result := OllamaResponse{}

	err = json.NewDecoder(response.Body).Decode(&result)
	if err != nil {
		fmt.Println("Error decoding JSON response:", err)
		// return nil, err
	}

	if result.Error != "" {
		fmt.Println("Error:", result.Error)
	}

	cleaned := strings.ReplaceAll(result.Response, "\n", "")

	return cleaned
}
